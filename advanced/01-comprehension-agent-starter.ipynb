{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "009a862d",
      "metadata": {},
      "source": [
        "# 01 â€” Comprehension Agent Starter\n",
        "\n",
        "**A stateful agent that remembers and builds comprehension over time.**\n",
        "\n",
        "This notebook is your playground for turning Natural Language Programming into persistent intelligence."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8674a03a",
      "metadata": {},
      "source": [
        "## Core Idea\n",
        "\n",
        "Instead of one-off prompts, the agent maintains a **knowledge graph** of your domain comprehension.\n",
        "\n",
        "Every rich prompt you feed it updates the shared mental model.\n",
        "\n",
        "Future tasks automatically inherit full context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b8a4042",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple in-memory comprehension agent (expand with LangGraph / vector DB later)\n",
        "\n",
        "class ComprehensionAgent:\n",
        "    def __init__(self):\n",
        "        self.knowledge = {}          # key concepts\n",
        "        self.history = []            # full conversation trace\n",
        "        self.priorities = {}         # domain priorities that never change\n",
        "\n",
        "    def ingest(self, nl_prompt: str):\n",
        "        \"\"\"Extract and store comprehension from a rich natural-language prompt\"\"\"\n",
        "        print(\"ðŸ¤– Ingesting full mental model...\")\n",
        "        self.history.append(nl_prompt)\n",
        "        # In real version: call LLM to extract structured knowledge\n",
        "        key = \"rate_limiter_privacy\"\n",
        "        self.knowledge[key] = \"GDPR: never store raw user identifiers; privacy > speed\"\n",
        "        print(\"âœ… Comprehension updated\")\n",
        "\n",
        "    def generate(self, task: str) -> str:\n",
        "        \"\"\"Generate with full accumulated comprehension\"\"\"\n",
        "        context = \"\\n\".join([f\"Priority: {k} = {v}\" for k, v in self.knowledge.items()])\n",
        "        full_prompt = f\"\"\"{context}\n",
        "\n",
        "Task: {task}\n",
        "Use all prior comprehension.\"\"\"\n",
        "        print(\"ðŸ¤– Generating with full context...\")\n",
        "        return f\"[LLM would return production code here using {full_prompt}]\"\n",
        "\n",
        "# Initialize your first agent\n",
        "agent = ComprehensionAgent()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e29b486f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage â€” run these cells in order\n",
        "agent.ingest(\"\"\"Build a rate-limiter for healthcare SaaS...\n",
        "(paste the full natural-language prompt here)\"\"\")\n",
        "\n",
        "result = agent.generate(\"Add a new endpoint for audit logging\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e160329",
      "metadata": {},
      "source": [
        "## Next Level Ideas (add your own cells)\n",
        "\n",
        "- Persist with JSON / SQLite\n",
        "- Add vector memory (Chroma / FAISS)\n",
        "- Hook into LangGraph or CrewAI\n",
        "- Make it multi-agent (one for compliance, one for performance, etc.)\n",
        "\n",
        "The more you feed it, the smarter and more valuable it becomes â€” exactly like the repo itself."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
